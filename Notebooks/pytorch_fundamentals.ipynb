{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDVmEzSsoniIFo9d0UkDeq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManantenaKiady/Pytorch-fundamentals/blob/master/Notebooks/pytorch_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What we will cover\n",
        "\n",
        "In this notebook, we will explore the building blocks of Pytorch \n",
        "- What is Pytorch ?\n",
        "- Why Pytorch ?\n",
        "- Installing Pytorch\n",
        "- Tensors\n",
        "- Learning Algorithms (Backpropagation)\n",
        "  - Forward and Backward Pass\n",
        "  - Auto-Grad\n",
        "  - Optimizers\n",
        "- Workflow\n",
        "  - Toy Project: Linear Regression\n",
        "- Datasets\n",
        "  - DataLoader"
      ],
      "metadata": {
        "id": "qW0i2hltaTvH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1- What is Pytorch\n",
        "\n",
        "It is an open source deep learning and machine learning framework developed by Meta (Facebook) and now in maintained by Linux Fundation community. \n",
        "\n",
        "Link: https://pytorch.org/\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fmQHHG-aEo_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2- Why Pytorch ?\n",
        "\n",
        "- Used by the worlds largest tech companies such as Meta (Facebook), Tesla, Microsoft and Open AI.\n",
        "\n",
        "- The most used deep learning framework in research.\n",
        "\n",
        "- Pythonic"
      ],
      "metadata": {
        "id": "8bkvGeIkF1Iv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3- Setup\n",
        "\n",
        "Setting up Pytorch 1.13.0, the latest stable release along with other needed libraries and packages."
      ],
      "metadata": {
        "id": "3CMW9YBCK2fb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To install Pytorch\n",
        "\n",
        "* Go to https://pytorch.org/get-started/locally/ and download the latest Pytorch release. Follows the instructions"
      ],
      "metadata": {
        "id": "mjffCWtOGlr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision torchaudio\n",
        "\n",
        "# Check the installed version \n",
        "import torch\n",
        "torch.__version__\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "T1e84HnmO-A7",
        "outputId": "dd5c334f-7a9d-4cf4-80f8-2c6117df5a7a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0+cu116)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (0.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.0+cu116'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure"
      ],
      "metadata": {
        "id": "D5PucLM_PFLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU are available and set the device to use it\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WOymlHgPEsO",
        "outputId": "f01ae3d0-1819-4991-e874-7aada40dc7c4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4- Tensors\n",
        "\n",
        "Tensors are a specialized data structure that are very similar to arrays and matrices. (Multidimentional Arrays)\n",
        " \n",
        "*Source: https://pytorch.org/tutorials/*\n",
        "\n",
        "eg of tensors: \n",
        "\n",
        "`scalar: 1`\n",
        "\n",
        "`vector: [1, 2, 3]`\n",
        "\n",
        "`matrices: [[1,2,3][4,5,6]]`"
      ],
      "metadata": {
        "id": "2jzRRc2fe_0t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tWn-SqNVaMtX"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize Tensors with `torch`"
      ],
      "metadata": {
        "id": "jOnP5mbghqp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From Python list**"
      ],
      "metadata": {
        "id": "PFeLQaeai5h9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of list in Python \n",
        "m = [[1,2,3],[4,5,6]]\n",
        "# Creating a tensor from list of list\n",
        "M = torch.tensor(m)\n",
        "\n",
        "print(f\"Type of m: {type(m)}\")\n",
        "print(f\"Type of M: {type(M)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWrfT_rnhZfd",
        "outputId": "ebd36491-dec6-4c01-c262-57a655c00832"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of m: <class 'list'>\n",
            "Type of M: <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From Arrays (Numpy)**\n",
        "\n",
        "What is numpy, who knows ?\n",
        "\n",
        "Source: https://numpy.org/"
      ],
      "metadata": {
        "id": "HwmnQftGjBS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "# Convert m into numpy array\n",
        "arr = np.array(m)\n",
        "print(f\"Type of arr: {type(arr)}\")\n",
        "# Transform arr into tensor\n",
        "ts_arr = torch.tensor(arr)\n",
        "print(f\"Type of ts_arr: {type(ts_arr)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL5gfvUrijmF",
        "outputId": "96c3a65e-4f1a-42a1-8c5c-41d474ee5d02"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of arr: <class 'numpy.ndarray'>\n",
            "Type of ts_arr: <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From another Tensor ?"
      ],
      "metadata": {
        "id": "jLxIsznMQcrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor Attributes**\n",
        "\n",
        "shape, dtype, device"
      ],
      "metadata": {
        "id": "_mm_5WVcPb0I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"green\"> Q1: Create a tensor from a python list and print all attributes ? </font>"
      ],
      "metadata": {
        "id": "OFzgoU7tPrx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------- Write your answer here --------"
      ],
      "metadata": {
        "id": "gqR2iI8yakLa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make a tensor use of a specific device, we can use the `to(device)` method."
      ],
      "metadata": {
        "id": "LnIdjdk-RSD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ts_arr.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38P6eJDbRcvj",
        "outputId": "391c3b65-26ac-428d-e74d-579fe098b7b0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ts_arr = ts_arr.to(device)\n",
        "print(f\"Tensor ts_arr is stored on: {ts_arr.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MWrZpioRjI_",
        "outputId": "4102e59c-1e8e-4f81-eb2c-95edabc2beba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor ts_arr is stored on: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Operations with Tensors**\n",
        "\n",
        "Indexing, Slicing, Sampling, math Operations, etc More [here](https://pytorch.org/docs/stable/torch.html)"
      ],
      "metadata": {
        "id": "6CTg-FTnQeJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indexing"
      ],
      "metadata": {
        "id": "jCByfTNRVUFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Indexing\n",
        "\n",
        "ts_rand = torch.rand(4,4)\n",
        "print(f\"Tensor rand = {ts_rand}\")\n",
        "print()\n",
        "# All rows of column 1\n",
        "print(f\"ts_rand[:,1] = {ts_rand[:,1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1okPsY3RBLX",
        "outputId": "e5e4b79c-83a3-4a4f-e084-91b411bf2376"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor rand = tensor([[0.9202, 0.2052, 0.3116, 0.0802],\n",
            "        [0.3180, 0.7750, 0.1885, 0.1199],\n",
            "        [0.0266, 0.1553, 0.7521, 0.8477],\n",
            "        [0.8316, 0.3009, 0.0238, 0.5542]])\n",
            "\n",
            "ts_rand[:,1] = tensor([0.2052, 0.7750, 0.1553, 0.3009])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concatenate or join"
      ],
      "metadata": {
        "id": "naE9jY2UVW9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate or join\n",
        "# Along the column\n",
        "ts_ccat = torch.cat([ts_rand, torch.ones(4,4)], dim=1)\n",
        "print(ts_ccat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeYLCbwYTG2e",
        "outputId": "a791fc5d-15bc-4c07-e9d7-322a4ed72657"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9202, 0.2052, 0.3116, 0.0802, 1.0000, 1.0000, 1.0000, 1.0000],\n",
            "        [0.3180, 0.7750, 0.1885, 0.1199, 1.0000, 1.0000, 1.0000, 1.0000],\n",
            "        [0.0266, 0.1553, 0.7521, 0.8477, 1.0000, 1.0000, 1.0000, 1.0000],\n",
            "        [0.8316, 0.3009, 0.0238, 0.5542, 1.0000, 1.0000, 1.0000, 1.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Math operations"
      ],
      "metadata": {
        "id": "6JzdmJ_uVZxP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='green'> Q2: Using multiplication operators with tensors ? </font>"
      ],
      "metadata": {
        "id": "Q47R7otgVIQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ts_res = ts_rand * ts_ccat\n",
        "# What going on ?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "49d5wKutUpvP",
        "outputId": "74c2994a-40b7-4333-a2e2-2b4c41d09925"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-e4db21c50a43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mts_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts_rand\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mts_ccat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# What going on ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (8) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ts_rand.matmul(ts_ccat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQQZfxvzUxo-",
        "outputId": "454068d3-b2be-4e23-f53a-31c54b14744c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9870, 0.4203, 0.5617, 0.4069, 1.5172, 1.5172, 1.5172, 1.5172],\n",
              "        [0.6438, 0.7312, 0.3897, 0.3446, 1.4014, 1.4014, 1.4014, 1.4014],\n",
              "        [0.7989, 0.4977, 0.6234, 1.1282, 1.7818, 1.7818, 1.7818, 1.7818],\n",
              "        [1.3225, 0.5742, 0.3469, 0.4300, 1.7104, 1.7104, 1.7104, 1.7104]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ts_x1 = torch.tensor([[1,2,3]])\n",
        "# Addition\n",
        "ts_x1 = ts_x1 + 1\n",
        "print(f\"ts_x1 = {ts_x1}\")\n",
        "# Substrcact\n",
        "ts_x1 = ts_x1 - 2\n",
        "print(f\"ts_x1 = {ts_x1}\")\n",
        "# Division\n",
        "ts_x1 = ts_x1 / 2\n",
        "print(f\"ts_x1 = {ts_x1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo8tvDxXHmfw",
        "outputId": "1bc92c1b-288b-4930-e058-606934977fe7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ts_x1 = tensor([[2, 3, 4]])\n",
            "ts_x1 = tensor([[0, 1, 2]])\n",
            "ts_x1 = tensor([[0.0000, 0.5000, 1.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inplace operations"
      ],
      "metadata": {
        "id": "klw8p-muaGK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ts_ccat.add_(5)"
      ],
      "metadata": {
        "id": "-rtRdaleZ8UF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding the max and min in tensors"
      ],
      "metadata": {
        "id": "26gt0sm1IRN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "ts_range = torch.arange(0, 100, 10)\n",
        "ts_range"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVSbCWw9IVLr",
        "outputId": "bd5595c3-2731-4807-f3d1-8bdc5cc6b7b9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Minimum: {ts_range.min()}\")\n",
        "print(f\"Maximum: {ts_range.max()}\")\n",
        "print(f\"Mean: {ts_range.type(torch.float32).mean()}\") # won't work without float datatype\n",
        "print(f\"Sum: {ts_range.sum()}\")\n",
        "\n",
        "# or\n",
        "torch.max(ts_range), torch.min(ts_range), torch.mean(ts_range.type(torch.float32)), torch.sum(ts_range)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpvpgtMkIfnj",
        "outputId": "96067f90-71c4-44ff-ede3-45c76cd3a75a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum: 0\n",
            "Maximum: 90\n",
            "Mean: 45.0\n",
            "Sum: 450\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(90), tensor(0), tensor(45.), tensor(450))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positional min/max"
      ],
      "metadata": {
        "id": "SGyYf1E2I2K1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns index of max and min values\n",
        "print(f\"Index of the max value: {ts_range.argmax()}\")\n",
        "print(f\"Index of the min value: {ts_range.argmin()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W-y8Z95I4Ny",
        "outputId": "866f0fad-2dcd-4af1-b4ce-1c6a48557207"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index of the max value: 9\n",
            "Index of the min value: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors to Numpy ndrrays"
      ],
      "metadata": {
        "id": "DYHZpoHzgSMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ts_x = torch.tensor([1,1,1])\n",
        "arr_x = ts_x.numpy()\n",
        "ts_x.add_(2)\n",
        "print(\"Check if the value of the array has changed as well\")\n",
        "print(ts_x.numpy() == arr_x)"
      ],
      "metadata": {
        "id": "48gK5pMOaP-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Casting Tensor Types"
      ],
      "metadata": {
        "id": "EWbDAdApJEiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ts_range.dtype\n",
        "# Change type to float32\n",
        "ts_range = ts_range.type(torch.float32)\n",
        "print(f\"New tensor type: {ts_range.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ3dJkOwJDw6",
        "outputId": "4c1c8c7b-d870-4bc3-bd16-75390ec24f74"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New tensor type: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshape Tensors"
      ],
      "metadata": {
        "id": "jnJtHsEIJueb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.arange(1, 10).reshape(1, 3, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvjmdwkVJ4Ui",
        "outputId": "02924eee-d213-4a11-c065-fc79de6dc39f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [4, 5, 6],\n",
              "         [7, 8, 9]]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='green'> Q3: Hum whats going on if we try to reshape ts_range? </font>"
      ],
      "metadata": {
        "id": "GD1Z72MqKS5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------- Find out ----------------"
      ],
      "metadata": {
        "id": "9F0p8rJ-KaAa"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Squeeze and Unsqueeze\n",
        "\n",
        "* Squeeze: Remove one dimension to a tensor\n",
        "* Unsqueeze: Add a new dimension to a tensor\n"
      ],
      "metadata": {
        "id": "v9AAQTzqWFDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ts_sq = torch.tensor([[[2],[1]],[[3],[1]]])\n",
        "print(ts_sq.shape)\n",
        "ts_sq = ts_sq.squeeze(dim=2)\n",
        "print(ts_sq)\n",
        "print(ts_sq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EinZyzbWEp9",
        "outputId": "45d73ebd-a5be-47dc-bf1a-08a264cead72"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2, 1])\n",
            "tensor([[2, 1],\n",
            "        [3, 1]])\n",
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unsqueeze\n",
        "ts_sq = ts_sq.unsqueeze(dim=2)\n",
        "print(ts_sq)\n",
        "print(ts_sq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee-wXm2xW8Wd",
        "outputId": "25647e0a-c7c9-41bb-c7c9-72b3f66cd71c"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[2]],\n",
            "\n",
            "         [[1]]],\n",
            "\n",
            "\n",
            "        [[[3]],\n",
            "\n",
            "         [[1]]]])\n",
            "torch.Size([2, 2, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='light_blue'> In deep learning and with Pytorch, inputs and outputs as well as weights and biases are represented with tensors </font>"
      ],
      "metadata": {
        "id": "S2BxIvFdb4T6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4- Designing Neural Network with Pytorch\n",
        "\n",
        "- import nn from torch\n",
        "- inherite nn.Module class\n",
        "- initialize layers under the`__init__` method\n",
        "- Add a ```forward``` method and specify how the data will pass throught the network.\n"
      ],
      "metadata": {
        "id": "BC3P1oulLFtk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Layers**\n",
        "\n",
        "Layers are defined in the `nn` module of pytorch, named based on their activation function.\n"
      ],
      "metadata": {
        "id": "dUIeEWRmOELp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l1 = nn.Linear(1,1)\n",
        "l2 = nn.ReLU(l1)\n",
        "l3 = nn.Sigmoid()\n",
        "l3 = nn.Conv2d(1, 28, 3)\n",
        "# Every function has its required parameters, always refers to the docs\n",
        "# For convolution find more on: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n"
      ],
      "metadata": {
        "id": "4AWUKPlbOrUz"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    # The super() function is used to give access to methods and properties of a parent or sibling class\n",
        "    super().__init__()\n",
        "    self.layer1 = nn.Linear(in_features=2, out_features=2)\n",
        "  \n",
        "  def forward(self, X):\n",
        "    # Here we pass the inputs through layer1\n",
        "    logits = self.layer1(X)\n",
        "    return logits\n",
        "\n",
        "model = NeuralNet()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qOfm2jlLuW2",
        "outputId": "b072f670-8b0a-4984-e658-71f637743435"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNet(\n",
            "  (layer1): Linear(in_features=2, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5- Learning Algorithm\n",
        "\n",
        "Training a Neural Network happens in two steps:\n",
        "\n",
        "*   **Forward Propagation**: It runs the input data through each layer and each activation of the network.\n",
        "*   **Backward Propagation**: The NN adjusts its parameters proportionate to the error in its guess. Traversing backwards from the output, *collecting the derivatives of the error with respect to the parameters of the functions*, and optimizing the parameters using gradient descent.\n",
        "\n",
        "More details [here](https://www.youtube.com/watch?v=tIeHLnjs5U8)\n",
        "\n"
      ],
      "metadata": {
        "id": "1p-pBMzNaFwk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='green'> Q5: Complete the following code </font>"
      ],
      "metadata": {
        "id": "7detYrRUMoPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First we need fully working Neural network\n",
        "\n",
        "# --------- Import the necessary package here -----------\n",
        "\n",
        "\n",
        "class NN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        # ----- Add two Linear layers here ---------\n",
        "        # First layers: in = 2, out = 2 \n",
        "        # Second layer: in = 2, out = 1\n",
        "    )\n",
        "  \n",
        "  def forward(self, X):\n",
        "    # --------- Add your code here ----------\n",
        "    outputs = ...\n",
        "    return outputs\n",
        "\n",
        "# Uncomment when complete\n",
        "\n",
        "model = NN().to(device)\n",
        "print(model)\n"
      ],
      "metadata": {
        "id": "0BkQ3MX6g4xN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ca39800-5c80-425a-ba55-d1cc3ba4d0eb"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN(\n",
            "  (layer_stack): Sequential(\n",
            "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
            "    (1): Linear(in_features=2, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.tensor([[1,2],[3,4]], dtype=torch.float).to(device)\n",
        "labels = torch.tensor([[0],[1]]).to(device)"
      ],
      "metadata": {
        "id": "NifIs-FQtEgJ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Forward Propagation**"
      ],
      "metadata": {
        "id": "YIZuzO7IfDG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward Pass\n",
        "prediction = model(data)\n",
        "print(f\"The shape of the output tensor: {prediction.shape}\")"
      ],
      "metadata": {
        "id": "SY9pGveWfMoO",
        "outputId": "f34e7a5a-2244-481f-eebf-bf8640985466",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the output tensor: torch.Size([2, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Prediction Errors - Loss**\n",
        "\n",
        "In practice, most of the cases, we use predefined Loss functions\n",
        "\n",
        "- MSELoss\n",
        "- CrossEntropyLoss\n",
        "- etc https://pytorch.org/docs/stable/nn.html\n"
      ],
      "metadata": {
        "id": "EDQKn2jFfR66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the loss, ie the error of the model given the prediction and the corresponding correct label\n",
        "loss = (prediction - labels).sum()\n",
        "print(f\"Loss = {loss}\")"
      ],
      "metadata": {
        "id": "2USRwy7DfcpQ",
        "outputId": "797d854c-4b49-4bde-fa48-03576ecea9da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss = -4.153697490692139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Backward Propagation - Autograd** "
      ],
      "metadata": {
        "id": "Gp9xfYrjfgTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Backpropagate the error through the network\n",
        "# By calling backward on the error tensor, the Autograd will be triggered\n",
        "# And the gradients for each model parameter are calculated and stored in the '.grad' attribute.\n",
        "# In practice, we set all gradients to zero before calculating -- optimizer.zero_grad()\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "421g2F6ufkjw"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Optimizers**\n",
        "Optimization Algorithms \n",
        "\n",
        "- Gradient Descent\n",
        "- Stochastic Gradient Descent (SGD)\n",
        "- Adam\n",
        "\n",
        "Find more on:\n",
        "https://pytorch.org/docs/stable/optim.html\n",
        "\n",
        "\n",
        "NB: Learning Rate (lr): step size at each iteration of the oprimization algorithm. (Hyperparameter) in French Pas d'apprentissage\n",
        "\n"
      ],
      "metadata": {
        "id": "CQjTZfJCf1Yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer: register model parameters\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "print(\"--------------------PARAMETERS----------------------\")\n",
        "print(f\"Parameters before update: {list(model.parameters())}\")\n",
        "# Then finally initiate the gradient descent algorithm ( here the SGD) and updates all models parameters\n",
        "# Set all gradients to zero before calculation\n",
        "optimizer.zero_grad()\n",
        "optimizer.step()\n",
        "print(\"----------------------------------------------------\")\n",
        "print(f\"Parameters after update: {list(model.parameters())}\")"
      ],
      "metadata": {
        "id": "18QLtIligEeq",
        "outputId": "4de3637f-3dda-4ee1-807c-5936154c18e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------PARAMETERS----------------------\n",
            "Parameters before update: [Parameter containing:\n",
            "tensor([[ 0.4559,  0.2453],\n",
            "        [-0.2297,  0.6165]], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([0.4971, 0.4653], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([[-0.0477, -0.4240]], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([-0.6880], device='cuda:0', requires_grad=True)]\n",
            "----------------------------------------------------\n",
            "Parameters after update: [Parameter containing:\n",
            "tensor([[ 0.4559,  0.2453],\n",
            "        [-0.2297,  0.6165]], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([0.4971, 0.4653], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([[-0.0477, -0.4240]], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([-0.6880], device='cuda:0', requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Frozen Parameters**\n",
        "\n",
        "In some cases, we don't need to update all parameters of the model, this is called **finetuning** in deep learning. To do so, we need to set the gradients to false for any parameters (Tensors) that are not required updates."
      ],
      "metadata": {
        "id": "K9DC_K7hymDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "  print(name)\n",
        "  param.requires_grad_(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDNSSIESd67e",
        "outputId": "915f8d87-8d35-4978-891b-f5f36405ddc6"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer_stack.0.weight\n",
            "layer_stack.0.bias\n",
            "layer_stack.1.weight\n",
            "layer_stack.1.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_parameter(\"layer_stack.0.weight\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFu2J7oYfr82",
        "outputId": "9f87dbb8-aa5e-466f-ade1-4946c36ca85c"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.4559,  0.2453],\n",
              "        [-0.2297,  0.6165]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6- Deep Learning Project Workflow ( With Pytorch )\n",
        "\n",
        "- Get the data\n",
        "- Split the data into train and test\n",
        "- Build a model\n",
        "- Train the model the fit the data\n",
        "- Evaluate the model\n",
        "- Save and reload\n",
        "- Make predictions\n",
        "\n",
        "\n",
        "In this section, we are going to build a simple linear regression model. \n",
        "\n",
        "y = ax + b"
      ],
      "metadata": {
        "id": "TjxPH3WBScQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create synthetic data\n",
        "\n",
        "noise = torch.rand(1, dtype=float)\n",
        "a = 0.7\n",
        "b = 0.3\n",
        "\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.03\n",
        "noise =  torch.rand(34).uniform_(0, 0.2)\n",
        "print(noise.shape)\n",
        "X = torch.arange(start, end, step)\n",
        "X.add_(noise)\n",
        "X.unsqueeze_(dim=1)\n",
        "y = a*X + b \n",
        "\n",
        "print(f\"X.shape = {X.shape}\")\n",
        "print(f\"y.shape= {y.shape}\")"
      ],
      "metadata": {
        "id": "GvQyFnH5vYzf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2da7727a-3710-484f-c2c5-fab0fcfe6704"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([34])\n",
            "X.shape = torch.Size([34, 1])\n",
            "y.shape= torch.Size([34, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split the data** into train and test"
      ],
      "metadata": {
        "id": "5u3bXZ4YYZkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 80% of data used for training set, 20% for testing \n",
        "train_split = int(0.8 * len(X)) \n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKzBXpR3YjZT",
        "outputId": "441174b3-5f30-407c-c234-73eec6167680"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27, 27, 7, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_data(pred=None):\n",
        "  if pred is not None:\n",
        "     plt.scatter(X_test, pred, c=\"r\", s=4, label=\"Predictions\")\n",
        "  plt.scatter(X_train, y_train, c=\"b\", s=4, label=\"Training data\")\n",
        "  plt.scatter(X_test, y_test, c=\"g\", s=4, label=\"Test data\")\n",
        "\n",
        "  plt.legend()\n",
        "\n",
        "plot_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "q3fSTyKHVRAD",
        "outputId": "e5a3ecb0-fd16-4cdf-c0ce-6fa5fb8b03ca"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAY3ElEQVR4nO3dfZBV9Z3n8feHBiQiUQNkozQGnEKBVuymW+LDVoRxk7SSgJnEKSicieYBJK3skswYkp2IcWK2TLImxVYbISlLZ6oMOkaniGKZ0cHCEpjYRCU0D4ZFJrS62nYMailC43f/uJf22k/3dvd9PP15VXX1Pef87j3f44WPh9/5nd9RRGBmZsk1otQFmJlZYTnozcwSzkFvZpZwDnozs4Rz0JuZJdzIUu14woQJMWXKlFLt3sysIm3fvv21iJg4kPeULOinTJlCS0tLqXZvZlaRJP3nQN/jrhszs4Rz0JuZJZyD3sws4UrWR9+bo0eP0tbWxuHDh0tdigFjxoyhurqaUaNGlboUMxuCsgr6trY2xo0bx5QpU5BU6nKGtYigo6ODtrY2pk6dWupyzGwIyqrr5vDhw4wfP94hXwYkMX78eP/ryiwByiroAYd8GfF3YZYMWYNe0p2SXpW0s4/t0yVtlfSupL/Lf4lmZsnR9HATI28eSdPDTUXbZy5n9HcBjf1s/xOwAvhxPgoqpY6ODmpra6mtreVjH/sYkyZN6lo+cuRIv+9taWlhxYoVWfdx0UUX5avcD5g7d27WG9B++tOf8vbbbxdk/2aWm7Xb13IsjrF2+9qi7TNr0EfEZlJh3tf2VyPiaeBoPgsrhfHjx/Pss8/y7LPPcu2117Jy5cqu5dGjR9PZ2dnnexsaGlizZk3WfWzZsiWfJQ+Ig96s9JbVL6NKVSyrX1a0fRa1j17SUkktklra29uLuetBu/rqq7n22mv5xCc+wQ033MBvf/tbLrzwQurq6rjooovYu3cvAE888QSf/exnAbjpppv48pe/zNy5cznzzDM/8D+Ak046qav93Llz+eIXv8j06dNZsmQJx5/2tXHjRqZPn059fT0rVqzo+txM77zzDosWLWLGjBl8/vOf55133unatnz5choaGqipqWH16tUArFmzhpdeeol58+Yxb968PtuZWWE1z2+m88ZOmuc3F22fRR1eGRHrgHUADQ0NFfMMw7a2NrZs2UJVVRVvvPEGTz75JCNHjuSxxx7jO9/5Dr/61a96vGfPnj1s2rSJN998k7PPPpvly5f3GI/+zDPP0Nrayumnn87FF1/MU089RUNDA8uWLWPz5s1MnTqVxYsX91rTz372M0488UR2797Njh07mD17dte2W265hY985CMcO3aMSy+9lB07drBixQpuu+02Nm3axIQJE/psN2vWrDz+lzOzclB2o24GqqkJRo5M/S6UK6+8kqqqKgAOHTrElVdeyTnnnMPKlStpbW3t9T3z58/nhBNOYMKECXz0ox/llVde6dFmzpw5VFdXM2LECGprazlw4AB79uzhzDPP7Bq73lfQb968mauuugqAWbNmfSCg77vvPmbPnk1dXR2tra3s2rWr18/ItZ2ZVbaKD/q1a+HYsdTvQhk7dmzX6+9+97vMmzePnTt38utf/7rPceYnnHBC1+uqqqpe+/dzaTNQL7zwAj/+8Y95/PHH2bFjB/Pnz++1xlzbmVnly2V45S+BrcDZktokfUXStZKuTW//mKQ24BvAP6TbfLiwZb9v2TKoqkr9LoZDhw4xadIkAO666668f/7ZZ5/N/v37OXDgAAD33ntvr+0++clPcs899wCwc+dOduzYAcAbb7zB2LFjOfnkk3nllVd45JFHut4zbtw43nzzzaztzGzgSjFsMldZ++gjove+g/e3/z+gOm8VDVBzc+qnWG644Qa+9KUv8f3vf5/58+fn/fM/9KEPcfvtt9PY2MjYsWM5//zze223fPlyrrnmGmbMmMGMGTOor68H4LzzzqOuro7p06czefJkLr744q73LF26lMbGRk4//XQ2bdrUZzszG7jMYZPFvNCaCx0f6VFsDQ0N0X3c9+7du5kxY0ZJ6iknb731FieddBIRQVNTE9OmTWPlypUlqcXfiVlumh5uYu32tSyrX1bQoJe0PSIaBvKesprUzFJ+/vOfc/fdd3PkyBHq6upYVqx+KTMbtOb5zWV3Jn+cg74MrVy5smRn8GaWPBU/6sbMzPrnoDczSzgHvZlZwjnozcwSzkGfYSjTFENqorJcZ6ecMmUKr732Wr9tfvCDH+T0WWZm/XHQZ8g2TXE2Awn6XDjozYqnnO9sHSoHfRbbt2/nkksuob6+ns985jO8/PLLQGra35kzZzJr1iwWLVrEgQMHuOOOO/jJT35CbW0tTz755Ac+p6Ojg09/+tPU1NTw1a9+lcwb1a644grq6+upqalh3bp1AKxatYp33nmH2tpalixZ0mc7M8uPUjwQpGgioiQ/9fX10d2uXbt6rCuV1atXxw9/+MO48MIL49VXX42IiPXr18c111wTERGnnXZaHD58OCIiXn/99a73/OhHP+r1866//vr43ve+FxERDz30UADR3t4eEREdHR0REfH2229HTU1NvPbaaxERMXbs2A98Rl/tCqmcvhOzQvr6Q1+Pqu9Vxdcf+nqpS+kX0BIDzNuKv2GqkLcdv/vuu+zcuZNPfepTABw7dozTTjsNSE0NvGTJEq644gquuOKKrJ+1efNmHnjgASA1hfGpp57atW3NmjU8+OCDABw8eJA//OEPjB8/vsdn5NrOzAaunO9sHaqK77op5D+3IoKampqufvrf//73/OY3vwHg4Ycfpqmpid/97necf/75g55i+IknnuCxxx5j69atPPfcc9TV1fU6XXCu7cysf0nui+9LxQd9IZ+/eMIJJ9De3s7WrVsBOHr0KK2trbz33nscPHiQefPmceutt3Lo0CHeeuutD0wD3F3mtMKPPPIIr7/+OpCa9vjUU0/lxBNPZM+ePWzbtq3rPaNGjeLo0aNZ25lZ7hLdF9+Hig/6Qj5/ccSIEdx///1861vf4rzzzqO2tpYtW7Zw7NgxrrrqKs4991zq6upYsWIFp5xyCp/73Od48MEHe70Yu3r1ajZv3kxNTQ0PPPAAZ5xxBgCNjY10dnYyY8YMVq1axQUXXND1nqVLl3Z1EfXXzsxyV4qHc5eapym2fvk7MSsvg5mmuOLP6M3MrH+5PErwTkmvStrZx3ZJWiNpn6Qdkmbnv0wzMxusXM7o7wIa+9l+GTAt/bMU+NlQCipVV5L15O/CLBmyBn1EbAb+1E+ThcA/pcfybwNOkXTaYIoZM2YMHR0dDpgyEBF0dHQwZsyYUpdiltVwHDI5EPm4YWoScDBjuS297uXuDSUtJXXW3zXqJFN1dTVtbW20t7fnoSwbqjFjxlBdXbLnvpvlrJwfzF0OinpnbESsA9ZBatRN9+2jRo1i6tSpxSzJzBJgWf2yrjvkrad8BP2LwOSM5er0OjOzokjy9AX5kI/hlRuAv02PvrkAOBQRPbptzMysNLKe0Uv6JTAXmCCpDVgNjAKIiDuAjcDlwD7gbeCaQhVrZmYDlzXoI2Jxlu0B+FK3mVmZ8p2xZmYJ56A3M0s4B72ZWcI56M3MEs5Bb2aWcA56M7OEc9CbmSWcg97MisazTJaGg97MimY4Ppi7HDjozaxohuODucuBg97MCqZ7V03z/GY6b+z0TJNF5qA3s4JxV015cNCbWcG4q6Y8qFTPZ21oaIiWlpaS7NvMrFJJ2h4RDQN5j8/ozcwSzkFvZoPW1AQjR6Z+W/ly0JvZoK1dC8eOpX5b+cop6CU1StoraZ+kVb1s/7ikxyXtkPSEpOr8l2pm5WbZMqiqSv228pX1YqykKuB54FNAG/A0sDgidmW0+RfgoYi4W9JfAtdExN/097m+GGtmNnCFuhg7B9gXEfsj4giwHljYrc1M4N/Trzf1st3MKpj74itbLkE/CTiYsdyWXpfpOeCv0q8/D4yTNH7o5ZlZOXBffGXL18XYvwMukfQMcAnwInCseyNJSyW1SGppb2/P067NrNDcF1/ZcumjvxC4KSI+k17+NkBE/K8+2p8E7ImIfi/Iuo/ezGzgCtVH/zQwTdJUSaOBRcCGbjueIOn4Z30buHMgRZiZWeFkDfqI6ASuAx4FdgP3RUSrpJslLUg3mwvslfQ88F+AWwpUr5mZDZDnujEzqyCe68bMzHpw0JuZJZyD3mwY8Y1Pw5OD3mwY8Y1Pw5OD3mwY8Y1Pw5OD3izBunfVNDdDZ2fqtw0fDnqzBHNXjYGD3ixRup/Bu6vGwDdMmSXKyJGpM/iqqlQXjSWPb5gyG+Z8Bm+98Rm9mVkF8Rm9mZn14KA3M0s4B72ZWcI56M3MEs5Bb2aWcA56M7OEc9CbmSVcTkEvqVHSXkn7JK3qZfsZkjZJekbSDkmX579UMzMbjKxBL6kKaAYuA2YCiyXN7NbsH0g9NLwOWATcnu9CzcxscHI5o58D7IuI/RFxBFgPLOzWJoAPp1+fDLyUvxLNzGwocgn6ScDBjOW29LpMNwFXSWoDNgLX9/ZBkpZKapHU0t7ePohyzcxsoPJ1MXYxcFdEVAOXA/8sqcdnR8S6iGiIiIaJEyfmaddmZtafXIL+RWByxnJ1el2mrwD3AUTEVmAMMCEfBZqZ2dDkEvRPA9MkTZU0mtTF1g3d2vwRuBRA0gxSQe++GTOzMpA16COiE7gOeBTYTWp0TaukmyUtSDf7JvA1Sc8BvwSujlLNf2xmZh+QUx99RGyMiLMi4i8i4pb0uhsjYkP69a6IuDgizouI2oj4TSGLNqsE3R/rZ1YqvjPWrED8YG4rFw56swLxY/2sXPhRgmZmFcSPEjQzsx4c9GZmCeegNxsEj6ixSuKgNxsEj6ixSuKgNxsEj6ixSuKgN8uit26a5mbo7Ez9Nit3DnqzLNxNY5XOQW+WhbtprNL5hikzswriG6bMBqmpCUaMAMlDJi15HPRmpPrfj//j1n3xljQOejNS/e/S+6/NksR99GZmFcR99GY58PQFNtzkFPSSGiXtlbRP0qpetv9E0rPpn+cl/Tn/pZrlh8fF23CTNeglVQHNwGXATGCxpJmZbSJiZfoRgrXA/wEeKESxZvngcfE23ORyRj8H2BcR+yPiCLAeWNhP+8WkHhBuVpY8fYENN7kE/STgYMZyW3pdD5I+DkwF/r2P7UsltUhqaW9vH2itZmY2CPm+GLsIuD8ijvW2MSLWRURDRDRMnDgxz7s2M7Pe5BL0LwKTM5ar0+t6swh321gJeUSNWU+5BP3TwDRJUyWNJhXmG7o3kjQdOBXYmt8SzXLnETVmPWUN+ojoBK4DHgV2A/dFRKukmyUtyGi6CFgfpboDywyPqDHrje+MNTOrIL4z1szMenDQm5klnIPezCzhHPRmZgnnoDczSzgHvZlZwjnorez47laz/HLQW1nIDHff3WqWXw56KwuZ4e67W83yy0FvZSEz3D1fvFl+eQoEM7MK4ikQzMysBwe9FY1H05iVhoPeisajacxKw0FvRePRNGal4YuxZmYVxBdjrSy4L96svOQU9JIaJe2VtE/Sqj7a/LWkXZJaJd2T3zKtkrgv3qy8ZA16SVVAM3AZMBNYLGlmtzbTgG8DF0dEDfA/ClCrVQj3xZuVl1zO6OcA+yJif0QcAdYDC7u1+RrQHBGvA0TEq/kt0yqJ72w1Ky+5BP0k4GDGclt6XaazgLMkPSVpm6TGfBVoZmZDMzKPnzMNmAtUA5slnRsRf85sJGkpsBTgjDPOyNOuzcysP7mc0b8ITM5Yrk6vy9QGbIiIoxHxAvA8qeD/gIhYFxENEdEwceLEwdZsZmYDkEvQPw1MkzRV0mhgEbChW5t/JXU2j6QJpLpy9uexTisDHjZpVpmyBn1EdALXAY8Cu4H7IqJV0s2SFqSbPQp0SNoFbAL+PiI6ClW0lYaHTZpVppz66CNiI7Cx27obM14H8I30jyXUsmXvPxjEzCqHp0AwM6sgngLBzMx6cNCbmSWcg97MLOEc9GZmCeegH4Y8Ht5seHHQD0MeD282vDjohyFPI2w2vHgcvZlZBfE4ejMz68FBb2aWcA56M7OEc9CbmSWcg97MLOEc9GZmCeegNzNLOAe9mVnCOegrSFMTjBgBkuepMbPc5RT0khol7ZW0T9KqXrZfLald0rPpn6/mv1RbuxaO38jseWrMLFdZg15SFdAMXAbMBBZLmtlL03sjojb984s812mk5qaR3n9tZpaLXM7o5wD7ImJ/RBwB1gMLC1uW9aa5Gd57L3VW39xc6mrMrFLkEvSTgIMZy23pdd19QdIOSfdLmtzbB0laKqlFUkt7e/sgyjUzs4HK18XYXwNTImIW8G/A3b01ioh1EdEQEQ0TJ07M067NzKw/uQT9i0DmGXp1el2XiOiIiHfTi78A6vNTnpmZDVUuQf80ME3SVEmjgUXAhswGkk7LWFwA7M5fiWZmNhQjszWIiE5J1wGPAlXAnRHRKulmoCUiNgArJC0AOoE/AVcXsGYzMxuAnProI2JjRJwVEX8REbek192YDnki4tsRURMR50XEvIjYU8iiK50fzm1mxeQ7Y0vAD+c2s2Jy0JeAH85tZsXkh4ObmVUQPxzczMx6cNAXiC+4mlm5cNAXiC+4mlm5cNDnUeZZvC+4mlm58MXYPBo5MnUWX1UFnZ2lrsbMksgXY0vMZ/FmVo4c9IPU28XW5ubUmbznijezcuKgHyRfbDWzSuGgH6DjZ/IzZribxswqQ9bZK+2Djp/J797tC65mVhl8Rj9AvuBqZpXGwyvNzCqIh1eamVkPDnozs4TLKeglNUraK2mfpFX9tPuCpJA0oH9WmJlZ4WQNeklVQDNwGTATWCxpZi/txgH/HfiPfBdpZmaDl8sZ/RxgX0Tsj4gjwHpgYS/t/hG4FTicx/rMzGyIcgn6ScDBjOW29LoukmYDkyPi4f4+SNJSSS2SWtrb2wdcrJmZDdyQL8ZKGgHcBnwzW9uIWBcRDRHRMHHixKHu2szMcpBL0L8ITM5Yrk6vO24ccA7whKQDwAXABl+QNTMrD7kE/dPANElTJY0GFgEbjm+MiEMRMSEipkTEFGAbsCAifDeUmVkZyBr0EdEJXAc8CuwG7ouIVkk3S1pQ6ALNzGxocprULCI2Ahu7rbuxj7Zzh16WmZnli++MNTNLOAe9mVnCJSLoe3usn5mZpSQi6P1YPzOzviUi6P0wEDOzvlVc0PfWTdPcnHqsX3Nz6eoyMytXFRf07qYxMxuYigt6d9OYmQ2MnxlrZlZB/MxYMzPrwUFvZpZwDnozs4Rz0JuZJZyD3sws4Rz0ZmYJ56A3M0u4ko2jl9QO/GdJdp5fE4DXSl1EASX9+MDHmBRJP8bjx/fxiJg4kDeWLOiTQlLLQG9eqCRJPz7wMSZF0o9xKMfnrhszs4Rz0JuZJZyDfujWlbqAAkv68YGPMSmSfoyDPj730ZuZJZzP6M3MEs5Bb2aWcA76HEhqlLRX0j5Jq3rZ/g1JuyTtkPS4pI+Xos6hyHaMGe2+ICkkVdwwtlyOUdJfp7/LVkn3FLvGocrhz+oZkjZJeib95/XyUtQ5WJLulPSqpJ19bJekNenj3yFpdrFrHKocjnFJ+th+L2mLpPOyfmhE+KefH6AK+L/AmcBo4DlgZrc284AT06+XA/eWuu58H2O63ThgM7ANaCh13QX4HqcBzwCnppc/Wuq6C3CM64Dl6dczgQOlrnuAx/hJYDaws4/tlwOPAAIuAP6j1DUX4Bgvyvgzelkux+gz+uzmAPsiYn9EHAHWAwszG0TEpoh4O724Daguco1DlfUY0/4RuBU4XMzi8iSXY/wa0BwRrwNExKtFrnGocjnGAD6cfn0y8FIR6xuyiNgM/KmfJguBf4qUbcApkk4rTnX5ke0YI2LL8T+j5Jg3DvrsJgEHM5bb0uv68hVSZxSVJOsxpv8JPDkiHi5mYXmUy/d4FnCWpKckbZPUWLTq8iOXY7wJuEpSG7ARuL44pRXNQP++Vrqc8mZkEQoZNiRdBTQAl5S6lnySNAK4Dbi6xKUU2khS3TdzSZ0lbZZ0bkT8uaRV5ddi4K6I+N+SLgT+WdI5EfFeqQuzgZE0j1TQ/9dsbX1Gn92LwOSM5er0ug+Q9N+A/wksiIh3i1RbvmQ7xnHAOcATkg6Q6vvcUGEXZHP5HtuADRFxNCJeAJ4nFfyVIpdj/ApwH0BEbAXGkJosKyly+vta6STNAn4BLIyIjmztHfTZPQ1MkzRV0mhgEbAhs4GkOmAtqZCvtH5dyHKMEXEoIiZExJSImEKqX3BBRLSUptxByfo9Av9K6mweSRNIdeXsL2aRQ5TLMf4RuBRA0gxSQd9e1CoLawPwt+nRNxcAhyLi5VIXlU+SzgAeAP4mIp7P5T3uuskiIjolXQc8SmpUw50R0SrpZqAlIjYAPwJOAv5FEsAfI2JByYoeoByPsaLleIyPAp+WtAs4Bvx9LmdL5SLHY/wm8HNJK0ldmL060sM3KoGkX5L6n/GE9HWG1cAogIi4g9R1h8uBfcDbwDWlqXTwcjjGG4HxwO3pvOmMLLNaegoEM7OEc9eNmVnCOejNzBLOQW9mlnAOejOzhHPQm5klnIPezCzhHPRmZgn3/wFsFohTA8D8NQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a Model"
      ],
      "metadata": {
        "id": "8sIQcH9Xbzo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class LinearRegressionModel(nn.Module): \n",
        "  def __init__(self):\n",
        "    super().__init__() \n",
        "    self.layer = nn.Linear(1,1)\n",
        "  def forward(self, x):\n",
        "    return self.layer(x)"
      ],
      "metadata": {
        "id": "RKrgPqeMVUN7"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegressionModel()"
      ],
      "metadata": {
        "id": "NiNu6S4FVWuH"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with model\n",
        "with torch.inference_mode():\n",
        "    pred = model(X_test)"
      ],
      "metadata": {
        "id": "tt1CoApOdbUc"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_data(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "sjxXxEI6d9h7",
        "outputId": "eeb2c10b-8850-420d-cde0-f0bac86ca891"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model\n",
        "\n",
        "- Define a loss function"
      ],
      "metadata": {
        "id": "bdKNv_FRergr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.L1Loss()\n",
        "# Define the optimizer\n",
        "optmizer = torch.optim.SGD(params=model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "UYNgavVud1je"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Set the number of epochs (how many times the model will pass over the training data)\n",
        "epochs = 1000\n",
        "\n",
        "# Create empty loss lists to track values\n",
        "train_loss_values = []\n",
        "test_loss_values = []\n",
        "epoch_count = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    ### Training\n",
        "\n",
        "    # Put model in training mode (this is the default state of a model)\n",
        "    model.train()\n",
        "\n",
        "    # 1. Forward pass on train data using the forward() method inside \n",
        "    y_pred = model(X_train)\n",
        "    # print(y_pred)\n",
        "\n",
        "    # 2. Calculate the loss (how different are our models predictions to the ground truth)\n",
        "    loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "    # 3. Zero grad of the optimizer\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backwards\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Progress the optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "    ### Testing\n",
        "\n",
        "    # Put the model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "      # 1. Forward pass on test data\n",
        "      test_pred = model(X_test)\n",
        "\n",
        "      # 2. Caculate loss on test data\n",
        "      test_loss = loss_fn(test_pred, y_test.type(torch.float))\n",
        "\n",
        "      # Print out what's happening\n",
        "      if epoch % 10 == 0:\n",
        "            epoch_count.append(epoch)\n",
        "            train_loss_values.append(loss.detach().numpy())\n",
        "            test_loss_values.append(test_loss.detach().numpy())\n",
        "            print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss} \")"
      ],
      "metadata": {
        "id": "VfIwegJLjRIa",
        "outputId": "56076be4-6d22-4972-c7de-b300dd45db15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 10 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 20 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 30 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 40 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 50 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 60 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 70 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 80 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 90 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 100 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 110 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 120 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 130 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 140 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 150 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 160 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 170 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 180 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 190 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 200 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 210 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 220 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 230 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 240 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 250 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 260 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 270 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 280 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 290 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 300 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 310 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 320 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 330 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 340 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 350 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 360 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 370 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 380 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 390 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 400 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 410 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 420 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 430 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 440 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 450 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 460 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 470 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 480 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 490 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 500 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 510 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 520 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 530 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 540 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 550 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 560 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 570 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 580 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 590 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 600 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 610 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 620 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 630 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 640 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 650 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 660 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 670 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 680 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 690 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 700 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 710 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 720 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 730 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 740 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 750 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 760 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 770 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 780 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 790 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 800 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 810 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 820 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 830 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 840 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 850 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 860 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 870 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 880 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 890 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 900 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 910 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 920 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 930 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 940 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 950 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 960 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 970 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 980 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n",
            "Epoch: 990 | MAE Train Loss: 1.6990548372268677 | MAE Test Loss: 2.5713589191436768 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with model\n",
        "with torch.inference_mode():\n",
        "    pred = model(X_test)\n",
        "\n",
        "plot_data(pred)"
      ],
      "metadata": {
        "id": "Iu3amQ71o5XO",
        "outputId": "53ddec33-a61f-4f2c-93f3-1add62779383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KlAhtUpDpCHH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}